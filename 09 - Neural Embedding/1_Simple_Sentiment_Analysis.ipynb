{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "1 - Simple Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8xL5h0xEuG"
      },
      "source": [
        "# 1 - Simple Sentiment Analysis\n",
        "\n",
        "We'll be building a machine learning model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SygB96RUxEuJ"
      },
      "source": [
        "## Preparing Data\n",
        "\n",
        "In our sentiment classification task the data consists of both the raw string of the review and the sentiment, either \"pos\" or \"neg\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAGJJKWfxEuL"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4iDbd54xEuT"
      },
      "source": [
        "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as `torchtext.datasets` objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXKjDbXixEuU",
        "outputId": "2c9c0101-a289-4834-dce2-5fed1edd05af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 147k/84.1M [00:00<01:06, 1.26MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 63.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKcs2kKmxEug",
        "outputId": "a11480e5-001a-41bf-8382-27c4f1555d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpgLI2xfxEuo",
        "outputId": "7da3e9af-a303-48bc-821c-3969f364c35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['\"', 'The', 'Blob', '\"', 'qualifies', 'as', 'a', 'cult', 'sci', '-', 'fi', 'film', 'not', 'only', 'because', 'it', 'launched', '27-year', 'old', 'Steve', 'McQueen', 'on', 'a', 'trajectory', 'to', 'superstardom', ',', 'but', 'also', 'because', 'it', 'exploited', 'the', 'popular', 'themes', 'both', 'of', 'alien', 'invasion', 'and', 'teenage', 'delinquency', 'that', 'were', 'inseparable', 'in', 'the', '1950s', '.', 'Interestingly', ',', 'nobody', 'in', 'the', 'Kay', 'Linaker', '&', 'Theodore', 'Simonson', 'screenplay', 'ever', 'refers', 'to', 'the', 'amorphous', ',', 'scarlet', '-', 'red', 'protoplasm', 'that', 'plummeted', 'to', 'Earth', 'in', 'a', 'meteor', 'and', 'menaced', 'everybody', 'in', 'the', 'small', 'town', 'of', 'Downingtown', 'Pennsylvania', 'on', 'a', 'Friday', 'night', 'as', '\"', 'The', 'Blob', '.', '\"', 'Steve', 'McQueen', 'won', 'the', 'role', 'of', 'Josh', 'Randall', ',', 'the', 'old', 'West', 'bounty', 'hunter', 'in', '\"', 'Wanted', ':', 'Dead', 'or', 'Alive', ',', '\"', 'after', 'producer', 'Dick', 'Powell', 'saw', 'this', 'Paramount', 'Pictures', \"'\", 'release', '.', 'Meanwhile', 'McQueen', \"'s\", 'attractive', 'girlfriend', 'Aneta', 'Corsaut', 'went', 'on', 'to', 'star', 'opposite', 'Andy', 'Griffith', 'in', '\"', 'The', 'Andy', 'Griffith', 'Show', '\"', 'as', 'Sheriff', 'Taylor', \"'s\", 'school', 'teacher', 'girlfriend', 'Helen', 'Crump', '.', 'Of', 'course', ',', 'neither', 'McQueen', 'nor', 'Corsaut', 'were', 'teenagers', ',', 'but', 'then', 'rarely', 'did', 'actual', 'teenagers', 'play', 'actual', 'teenagers', '.', 'Director', 'Irvin', 'S.', 'Yeaworth', ',', 'Jr.', ',', 'made', 'his', 'directorial', 'debut', 'with', '\"', 'The', 'Blob', '.', '\"', 'Linaker', '&', 'Simonson', \"'s\", 'screenplay', 'synthesized', 'four', 'genres', ':', 'first', ',', 'the', 'alien', 'invasion', ';', 'second', ',', 'teenage', 'delinquency', ';', 'third', ',', 'a', 'murder', 'mystery', ',', 'and', 'fourth', ';', 'a', 'horror', 'chiller', '.', 'Moreover', ',', 'while', 'the', 'gelatinous', 'substance', 'assumes', 'various', 'shapes', ',', 'it', 'remains', 'largely', 'anonymous', '.', 'In', 'other', 'words', ',', 'the', 'eponymous', 'Jell', '-', 'O', 'neither', 'talks', 'nor', 'communicates', 'by', 'telepathy', '.', 'Instead', ',', 'it', 'kills', 'without', 'a', 'qualm', 'and', 'discriminates', 'against', 'nobody', '.', 'The', 'tone', 'of', '\"', 'The', 'Blob', '\"', 'is', 'fairly', 'serious', 'in', 'spite', 'of', 'its', 'somewhat', 'campy', 'nature.<br', '/><br', '/>As', 'the', 'filmmakers', 'point', 'out', 'on', 'the', 'Criterion', 'DVD', 'release', 'of', '\"', 'The', 'Blob', ',', '\"', 'the', 'movie', 'opens', 'uncharacteristically', 'for', 'a', 'sci', '-', 'fi', 'horror', 'thriller', 'with', 'our', 'hero', 'and', 'heroine', 'in', 'a', 'remote', 'rural', 'locale', 'making', 'out', 'and', 'kissing', '.', 'Jane', '(', 'Anita', 'Corsaut', ')', 'and', 'Steve', '(', 'Steve', 'McQueen', ')', 'see', 'a', 'large', 'meteor', 'fall', 'to', 'the', 'earth', 'and', 'drive', 'off', 'to', 'find', 'it', '.', 'Meanwhile', ',', 'an', 'old', 'man', 'finds', 'the', 'meteor', 'and', 'prods', 'it', 'with', 'a', 'stick', '.', 'The', 'meteor', 'cracks', 'open', 'and', 'a', 'slimy', 'bunch', 'of', 'goop', 'clings', 'to', 'the', 'stick', '.', 'When', 'the', 'old', 'timer', '(', 'Olin', 'Howland', 'of', '\"', 'The', 'Paleface', '\"', ')', 'gets', 'a', 'closer', 'look', 'at', 'it', ',', 'the', 'goop', 'attaches', 'itself', 'to', 'his', 'hand', '.', 'The', 'old', 'guy', 'runs', 'screaming', 'from', 'the', 'crater', 'and', 'Steve', 'nearly', 'hits', 'him', 'with', 'his', 'jalopy', '.', 'Steve', 'and', 'Jane', 'pick', 'the', 'guy', 'up', 'and', 'take', 'him', 'to', 'see', 'Dr.', 'Hallen', 'in', 'town', '.', '<', 'br', '/><br', '/>Hallen', 'is', 'poised', 'to', 'leave', 'town', 'for', 'a', 'medical', 'conference', 'when', 'Steve', 'and', 'Jane', 'bring', 'the', 'old', 'guy', 'to', 'his', 'office', '.', 'Hallen', 'phones', 'his', 'nurse', 'to', 'return', 'since', 'he', 'may', 'need', 'to', 'perform', 'an', 'amputation', '.', 'Of', 'course', ',', 'Hallen', 'has', 'never', 'seen', 'anything', 'like', 'the', 'substance', 'on', 'the', 'man', \"'s\", 'forearm', '.', 'Hallen', 'sends', 'Steve', 'and', 'Jane', 'to', 'find', 'out', 'what', 'happened', '.', 'Our', 'heroes', 'run', 'into', 'another', 'group', 'of', 'teenagers', 'that', 'ridicule', 'Steve', \"'s\", 'fast', 'driving', '.', 'Steve', 'fools', 'him', 'into', 'a', 'reverse', 'drive', 'race', ',', 'but', 'the', 'local', 'police', 'chief', 'Dave', '(', 'Earl', 'Rowe', ')', 'lets', 'him', 'off', 'the', 'hook', '.', 'Steve', 'and', 'the', 'teenagers', 'visit', 'the', 'site', 'of', 'the', 'meteor', 'crater', 'and', 'find', 'the', 'warm', 'remains', 'of', 'the', 'meteor', '.', 'After', 'they', 'visit', 'the', 'old', 'man', \"'s\", 'house', 'and', 'rescue', 'a', 'dog', ',', 'the', 'teenagers', 'split', 'for', 'a', 'spooky', 'late', 'night', 'movie', 'while', 'Steve', 'and', 'Jane', 'return', 'to', 'Dr.', 'Hallen', \"'s\", 'office', '.', 'During', 'the', 'interim', ',', 'the', 'blob', 'has', 'entirely', 'absorbed', 'the', 'old', 'geezer', ',', 'killed', 'Hallen', \"'s\", 'nurse', 'and', 'attacked', 'the', 'doctor', '.', 'Neither', 'acid', 'thrown', 'on', 'the', 'protoplasm', 'nor', 'Hallen', \"'s\", 'shotgun', 'have', 'any', 'effect', 'on', 'the', 'blob', '.', 'Steve', 'catches', 'a', 'glimpse', 'of', 'the', 'blob', 'absorbing', 'Hallen', '.', 'When', 'Steve', 'and', 'Jane', 'go', 'to', 'the', 'police', 'department', 'to', 'report', 'the', 'incident', ',', 'Dave', 'is', 'frankly', 'incredulous', ',', 'while', 'Sergeant', 'Bert', '(', 'John', 'Benson', ')', 'believes', 'that', 'it', 'is', 'a', 'prank', '.', 'Bert', 'has', 'an', 'axe', 'to', 'grind', 'with', 'teenagers', 'because', 'his', 'wife', 'died', 'when', 'one', 'struck', 'her', 'car.<br', '/><br', '/>Steve', 'and', 'Jane', 'take', 'them', 'to', 'Hallen', \"'s\", 'office', ',', 'but', 'they', 'can', 'find', 'neither', 'hide', 'nor', 'hair', 'of', 'anybody', ',', 'but', 'Dave', 'admits', 'that', 'the', 'office', 'has', 'been', 'vandalized', '.', 'Against', 'Sgt', '.', 'Bert', \"'s\", 'advice', ',', 'Dave', 'turns', 'the', 'teens', 'over', 'to', 'their', 'respective', 'parents', '.', 'No', 'sooner', 'have', 'Steve', 'and', 'Jane', 'fooled', 'their', 'folks', 'into', 'believing', 'that', 'they', 'are', 'snugly', 'asleep', 'in', 'bed', 'than', 'they', 'venture', 'out', 'again', '.', 'They', 'drive', 'into', 'town', 'and', 'spot', 'the', 'old', 'man', \"'s\", 'dog', 'that', 'got', 'away', 'from', 'them', 'in', 'front', 'of', 'a', 'supermarket', '.', 'When', 'they', 'go', 'to', 'retrieve', 'the', 'mutt', ',', 'Steve', 'steps', 'in', 'front', 'of', 'the', 'electric', 'eye', 'door', 'of', 'the', 'grocery', 'store', 'and', 'it', 'opens', '.', 'They', 'find', 'nobody', 'inside', ',', 'but', 'they', 'encounter', 'the', 'blob', '.', 'Steve', 'and', 'Jane', 'take', 'refuge', 'in', 'a', 'freezer', 'and', 'the', 'blob', 'does', \"n't\", 'attack', 'them', '.', 'Later', ',', 'after', 'they', 'escape', ',', 'Steve', 'persuades', 'the', 'teenagers', 'that', 'challenged', 'him', 'in', 'a', 'street', 'race', 'to', 'alert', 'the', 'authorities', 'because', 'he', 'is', 'supposed', 'to', 'be', 'home', 'in', 'bed', '.', 'Police', 'Chief', 'Dave', 'and', 'the', 'fire', 'department', 'arrive', 'at', 'the', 'supermarket', '.', 'Steve', 'tries', 'to', 'convince', 'Dave', 'that', 'the', 'blob', 'is', 'in', 'the', 'store', '.', 'About', 'that', 'time', ',', 'the', 'blob', 'kills', 'the', 'theater', 'projectionist', 'and', 'attacks', 'the', 'moviegoers', '.', 'Suddenly', ',', 'a', 'horde', 'of', 'people', 'exit', 'the', 'theater', 'and', 'Dave', 'believes', 'Steve', '.', 'Steve', 'and', 'Jane', 'wind', 'up', 'at', 'a', 'lunch', 'counter', 'that', 'the', 'blob', 'attacks', '.', 'The', 'proprietor', 'and', 'our', 'heroes', 'hole', 'up', 'in', 'the', 'cellar', 'and', 'Steve', 'discovers', 'that', 'a', 'fire', 'extinguisher', 'with', 'its', 'freezing', 'contents', 'forces', 'the', 'blob', 'to', 'back', 'off.<br', '/><br', '/>The', 'authorities', 'collect', 'every', 'fire', 'extinguisher', 'in', 'town', 'and', 'manage', 'to', 'freeze', 'the', 'blob', '.', 'The', 'Pentagon', 'sends', 'down', 'a', 'team', 'to', 'transport', 'the', 'blob', 'to', 'the', 'North', 'Pole', '.', 'As', 'the', 'remains', 'of', 'the', 'blob', 'drift', 'down', 'to', 'the', 'polar', 'ice', 'pack', ',', 'the', 'end', 'credit', 'appears', 'with', 'a', 'ghostly', 'giant', 'question', 'mark', '.', 'Producer', 'James', 'B.', 'Harris', 'obtained', 'stock', 'military', 'footage', 'of', 'a', 'Globe', 'master', 'military', 'transport', 'plane', 'depositing', 'the', 'parachute', 'and', 'its', 'cargo.<br', '/><br', '/>\"The', 'Blob', '\"', 'proved', 'to', 'be', 'a', 'drive', '-', 'in', 'hit', 'and', 'Steve', 'McQueen', \"'s\", 'surge', 'to', 'stardom', 'gave', 'the', 'film', 'added', 'momentum', '.', 'Unless', 'you', 'are', 'a', 'juvenile', ',', 'this', 'little', 'horror', 'movie', 'is', \"n't\", 'scary', 'at', 'all', ',', 'but', 'Yeaworth', 'and', 'his', 'scenarists', 'create', 'a', 'sufficient', 'amount', 'of', 'paranoia', 'and', 'sympathy', 'for', 'our', 'heroes', '.', 'They', 'never', 'show', 'the', 'blob', 'actually', 'assimilating', 'its', 'victims', 'and', 'leave', 'this', 'to', 'your', 'imagination', ',', 'so', '\"', 'The', 'Blob', '\"', 'is', \"n't\", 'without', 'a', 'modicum', 'of', 'subtlety', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukEv42hIxEuu"
      },
      "source": [
        "By default this splits 70/30."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWij3gVoxEuv"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOR3sB2SxEu2",
        "outputId": "60eb2526-14b1-47eb-c274-7ebb27e59f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGb0FCdQxEvC"
      },
      "source": [
        "Next, we have to build a _vocabulary_. This is a effectively a look up table where every unique word in your data set has a corresponding _index_ (an integer).\n",
        "\n",
        "Will will keep the top 25,000 frequently occuring words.\n",
        "\n",
        "Other words are replaced with a special _unknown_ or `<unk>` token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL7krAIPxEvD"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMYGDAb5xEvI",
        "outputId": "0afe3189-32b0-42a4-da2a-7aa9d338d284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TBy_JE4xEvN"
      },
      "source": [
        "The vocab size 25002 because of the addition tokens `<unk>` and `<pad>`.\n",
        "\n",
        "We can also view the most common words in the vocabulary and their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBXiGm2RxEvO",
        "outputId": "01ae5275-01e9-4982-fbc5-ec6fb381addf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 202946), (',', 192199), ('.', 165679), ('and', 109101), ('a', 109053), ('of', 100868), ('to', 93689), ('is', 76235), ('in', 61202), ('I', 54694), ('it', 53717), ('that', 49349), ('\"', 44319), (\"'s\", 43396), ('this', 42128), ('-', 37113), ('/><br', 35607), ('was', 34975), ('as', 30510), ('with', 29816)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44-0H_YAxEvR"
      },
      "source": [
        "We can also see the vocabulary directly using either the `stoi` (**s**tring **to** **i**nt) or `itos` (**i**nt **to**  **s**tring) method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz8L11-BxEvS",
        "outputId": "713ea249-3ab0-42e4-d2fd-7dc7c1cfeb4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pycuV4DPxEvW"
      },
      "source": [
        "We can also check the labels, ensuring 0 is for negative and 1 is for positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-7fFaXOxEvX",
        "outputId": "faafc8c2-e2de-441f-fcd0-595502fcce99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f6ddd717ae8>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8z1ZLTxxEvb"
      },
      "source": [
        "Now we will create the data iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PyzV7Q-xEvc"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuIgRjE6xEvg"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq504h2gxEvh"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fCaPeIxxEvl"
      },
      "source": [
        "We now create an instance of our RNN class. \n",
        "\n",
        "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size. \n",
        "\n",
        "The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
        "\n",
        "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
        "\n",
        "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrWNe26zxEvm"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEpec6fOxEvq"
      },
      "source": [
        "Let's also create a function that will tell us how many trainable parameters our model has so we can compare the number of parameters across different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0epsOLxZxEvq",
        "outputId": "b73f58a1-33d8-4ff7-ed0f-f92404a1e78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjVAbLE0xEvv"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX-vWwNixEvw"
      },
      "source": [
        "Now we'll set up the training and then train the model.\n",
        "\n",
        "First, we'll create an optimizer. Here, we'll use _stochastic gradient descent_ (SGD)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uWheX1hxEvx"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmuXYVAxEv1"
      },
      "source": [
        "Next, we'll define our loss function. The loss function here is _binary cross entropy with logits_. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkPA0xpfxEv2"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj5uhZ2IxEv7"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PME3IpsqxEv-"
      },
      "source": [
        "Function for calculating model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_hdUYxkxEv_"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAuPG8WRJWns"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM1r8uA_xEwC"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWpYFD_SxEwI"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGqBgH_vxEwJ"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyTpyCZMxEwP"
      },
      "source": [
        "We'll also create a function to tell us how long an epoch takes to compare training times between models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtK0jYG7xEwQ"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84Q6dyhxEwW",
        "outputId": "efd3d316-d2c8-418a-82a1-c44bc2209a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.694 | Train Acc: 50.09%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 49.54%\n",
            "Epoch: 02 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.60%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 49.49%\n",
            "Epoch: 03 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.10%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 51.10%\n",
            "Epoch: 04 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.91%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 49.46%\n",
            "Epoch: 05 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.13%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 50.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OeWzDdexEwZ"
      },
      "source": [
        "The model does not perform well due to the simpleness of model architecture.\n",
        "\n",
        "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHOKp8-XxEwa",
        "outputId": "2b37403e-b777-44e7-ae66-4b36d2e87455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.712 | Test Acc: 45.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42046HUr14t3"
      },
      "source": [
        "## Save the Model\n",
        "Let's save the model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9uBsatu13oT"
      },
      "source": [
        "cpu_model = model.to('cpu')\n",
        "torch.save(cpu_model.state_dict(), 'simple_sentiment_analysis.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIvvHISh7gn9"
      },
      "source": [
        "Save model metadata\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxrvgp7J2Q3X"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('simple_sentiment_analysis_metadata.pkl', 'wb') as f:\n",
        "    metadata = {\n",
        "        'input_stoi': TEXT.vocab.stoi,\n",
        "        'label_itos': LABEL.vocab.itos,\n",
        "    }\n",
        "\n",
        "    pickle.dump(metadata, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whrO1tE4BORd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}